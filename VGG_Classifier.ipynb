{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_loader import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_size = int(0.8 * len(remaining_dataset))\n",
    "test_size = len(remaining_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(remaining_dataset,\n",
    "                                                            [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)#, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)#, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, num_epochs):\n",
    "    # def loss_fun(output, target):\n",
    "    #     return F.cross_entropy(output, target)\n",
    "    out_dict = {'train_acc': [],\n",
    "              'test_acc': [],\n",
    "              'train_loss': [],\n",
    "              'test_loss': [],\n",
    "              'y_pred': [],\n",
    "              'y_true': [],\n",
    "              'SEM': []}\n",
    "  \n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "                       \n",
    "            #Compute the loss\n",
    "            loss = loss_fn(target, output)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(dim=1)\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "        #Comput the test accuracy\n",
    "        test_loss = []\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            test_loss.append(loss_fn(target, output).cpu().item())\n",
    "            predicted = output.argmax(1)\n",
    "            test_correct += (target==predicted).sum().cpu().item()\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "        out_dict['train_acc'].append(train_correct/len(train_dataset))\n",
    "        out_dict['test_acc'].append(test_correct/len(test_dataset))\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['test_loss'].append(np.mean(test_loss))\n",
    "        out_dict['y_pred'].append(y_pred)\n",
    "        out_dict['y_true'].append(y_true)\n",
    "        std = 1 - accuracy_score(y_true, y_pred)\n",
    "        sem = std / np.sqrt(len(y_true))\n",
    "        sem_p = (sem / 1)\n",
    "        out_dict['SEM'].append(sem_p)\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(test_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100:.1f}%\\t test: {out_dict['test_acc'][-1]*100:.1f}%\\t\", f\"SEM: {out_dict['SEM'][-1]*100:.1f}%\\t\")\n",
    "        torch.save(model, 'model_CNN.pth')\n",
    "    return out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy(target, output):\n",
    "    return F.cross_entropy(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.classifier[-1].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 5)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(lr=1e-3, params=model.parameters(), weight_decay=0.1)\n",
    "output_dict = train(model, optimizer, CrossEntropy, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = output_dict['train_acc']\n",
    "test_acc = output_dict['test_acc']\n",
    "train_loss = output_dict['train_loss']\n",
    "test_loss = output_dict['test_loss']\n",
    "y_pred = output_dict['y_pred']\n",
    "y_true = output_dict['y_true']\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy plot')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.plot(epochs, test_loss, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss plot')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred_validation = []\n",
    "y_true_validation = []\n",
    "\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(x_test)\n",
    "    predicted = output.argmax(dim = 1)\n",
    "y_pred_validation.extend(predicted.cpu().numpy())\n",
    "y_true_validation.extend(y_test.cpu().numpy())\n",
    "\n",
    "\n",
    "std_val = 1 - accuracy_score(y_true_validation, y_pred_validation)\n",
    "sem_val = std_val / np.sqrt(len(y_true_validation))\n",
    "sem_p_val = (sem_val / 1) * 100\n",
    "print(accuracy_score(y_true_validation, y_pred_validation) * 100, sem_p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_true_validation, y_pred_validation, labels=[0,1,2,3,4], normalize = 'true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [\"stage W\", \"Stage 1\", \"Stage 2\", \"Stage 3/4\", \"Stage R\"])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_validation, y_pred_validation, target_names=['sleep stage W', 'sleep Stage 1', 'sleep Stage 2', 'Sleep Stage 3/4', 'Sleep Stage R']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
